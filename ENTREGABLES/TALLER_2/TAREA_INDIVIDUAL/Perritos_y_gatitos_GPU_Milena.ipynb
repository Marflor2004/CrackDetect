{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Instalaci贸n del paquete `kaggle`\n",
        "\n",
        "El siguiente comando instala la biblioteca `kaggle` en el entorno de Google Colab:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qysebIP01GGN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m2TwL79z60c",
        "outputId": "1081671c-1be9-427a-efdd-25255ffae633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Subida de Archivos a Google Colab\n",
        "\n",
        "El siguiente c贸digo se utiliza para subir archivos desde tu computadora local al entorno de Google Colab.\n",
        "\n",
        "### 1. Importaci贸n del M贸dulo `files` desde `google.colab`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nKN-LcRV1WhF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "MV6hxNit0ZBA",
        "outputId": "5b1c06d8-6f5e-4214-8189-2f47df906026"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a35d9dbe-be70-4a43-ac27-ef9530d1348b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a35d9dbe-be70-4a43-ac27-ef9530d1348b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5c2e8a8d365b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    165\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rG0iNZlX-Gvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "### Configuraci贸n de las Credenciales de Kaggle\n",
        "\n",
        "El siguiente conjunto de comandos se utiliza para configurar las credenciales de Kaggle en un entorno de Google Colab. Esto es necesario para poder descargar datasets y participar en competiciones directamente desde Kaggle usando scripts de Python.\n",
        "\n",
        "### 1. Crear un Directorio `.kaggle`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_DX0LBk81YTs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L4iZGMws0dX5"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "### Descarga y Descompresi贸n de un Dataset desde Kaggle\n",
        "\n",
        "Este conjunto de comandos se utiliza para descargar un dataset de Kaggle y descomprimirlo en el entorno de Google Colab.\n",
        "\n",
        "### 1. Descargar un Dataset desde Kaggle\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zGgXrOyS1aVO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RDOW3jP00ghh"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d hongweicao/catanddogsmall\n",
        "!unzip catanddogsmall.zip -d cats_and_dogs_small"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "### Actualizaci贸n de TensorFlow\n",
        "\n",
        "El siguiente comando se utiliza para actualizar la biblioteca `TensorFlow` a su 煤ltima versi贸n en el entorno de Google Colab.\n",
        "\n",
        "### 1. Actualizaci贸n de TensorFlow\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sIZsmciR1azv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qHmvCpUoAeRk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1dGvp_wC0ocY"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "### Verificaci贸n de GPUs Disponibles\n",
        "\n",
        "El siguiente c贸digo se utiliza para verificar cu谩ntas GPUs est谩n disponibles en el entorno de Google Colab.\n",
        "\n",
        "### 1. Importaci贸n del M贸dulo `tensorflow`\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "awMp50Ee1bG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "glq-Z9Nq2dhg"
      },
      "outputs": [],
      "source": [
        "# Verificar entorno de ejecuci贸n\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Configuraci贸n de Matplotlib para la Visualizaci贸n de Gr谩ficos\n",
        "\n",
        "El siguiente c贸digo se utiliza para configurar c贸mo se muestran los gr谩ficos generados con Matplotlib en un entorno de notebook, como Google Colab.\n",
        "\n",
        "### 1. Mostrar Gr谩ficos Inline\n",
        "\n"
      ],
      "metadata": {
        "id": "EEu1rW5R1b6R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KBwG2QA63HNJ"
      },
      "outputs": [],
      "source": [
        "#Configurar el entorno de ejecuci贸n\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Importaci贸n de Bibliotecas para An谩lisis y Visualizaci贸n de Datos\n",
        "\n",
        "El siguiente c贸digo importa varias bibliotecas esenciales para an谩lisis y visualizaci贸n de datos, y establece un estilo gr谩fico para Matplotlib.\n",
        "\n",
        "### 1. Importar `matplotlib.pyplot`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hv7_MPqp1dL1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ulf2guZq3KNi"
      },
      "outputs": [],
      "source": [
        "#Importaci贸n de librerias\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Configuraci贸n de la Gesti贸n de Advertencias\n",
        "\n",
        "El siguiente c贸digo se utiliza para configurar el manejo de advertencias en un entorno de Python.\n",
        "\n",
        "### 1. Importar el M贸dulo `warnings`\n",
        "\n"
      ],
      "metadata": {
        "id": "hhD23RAn1dzG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2HH5Mawh_dN8"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Configuraci贸n de Opciones de Visualizaci贸n de Pandas\n",
        "\n",
        "El siguiente c贸digo configura c贸mo se muestran los datos en los DataFrames de `pandas`, ajustando el formato de los n煤meros y el n煤mero m谩ximo de filas y columnas que se pueden visualizar.\n",
        "\n",
        "### 1. Configurar el Formato de los N煤meros Flotantes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fOM7Vr5g1ecH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2frZSXvgAGdj"
      },
      "outputs": [],
      "source": [
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 200)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Importaci贸n de Componentes de Keras para Modelado y Preprocesamiento\n",
        "\n",
        "El siguiente c贸digo importa diversas clases y funciones de la biblioteca `tensorflow.keras`, que se utiliza para construir, entrenar y evaluar modelos de deep learning, as铆 como para preprocesar datos de im谩genes.\n",
        "\n",
        "### 1. Importar Modelos y Funciones de Keras\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fiVsis8F1fK4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JrTJL2RsAOXT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Funciones para Procesamiento y Visualizaci贸n en Modelos de Deep Learning\n",
        "\n",
        "A continuaci贸n se describen varias funciones 煤tiles para el an谩lisis y procesamiento de datos de entrenamiento en modelos de deep learning.\n"
      ],
      "metadata": {
        "id": "_XTFqBp11fle"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P1R-wLycMCZT"
      },
      "outputs": [],
      "source": [
        "def smooth_curve(points, factor=0.8):\n",
        "    smoothed = []\n",
        "    for point in points:\n",
        "        if smoothed:\n",
        "            previous = smoothed[-1]\n",
        "            smoothed.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed.append(point)\n",
        "    return smoothed\n",
        "\n",
        "def plot_compare(history, steps=-1):\n",
        "    if steps < 0:\n",
        "        steps = len(history.history.get('accuracy', []))\n",
        "    acc = smooth_curve(history.history.get('accuracy', [])[:steps])\n",
        "    val_acc = smooth_curve(history.history.get('val_accuracy', [])[:steps])\n",
        "    loss = smooth_curve(history.history.get('loss', [])[:steps])\n",
        "    val_loss = smooth_curve(history.history.get('val_loss', [])[:steps])\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(loss, c='#0c7cba', label='Train Loss')\n",
        "    plt.plot(val_loss, c='#0f9d58', label='Val Loss')\n",
        "    plt.xticks(range(0, len(loss), max(1, len(loss)//10)))\n",
        "    plt.xlim(0, len(loss))\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'Train Loss: {loss[-1]:.3f}, Val Loss: {val_loss[-1]:.3f}', fontsize=12)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(acc, c='#0c7cba', label='Train Acc')\n",
        "    plt.plot(val_acc, c='#0f9d58', label='Val Acc')\n",
        "    plt.xticks(range(0, len(acc), max(1, len(acc)//10)))\n",
        "    plt.xlim(0, len(acc))\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(f'Train Accuracy: {acc[-1]:.3f}, Val Accuracy: {val_acc[-1]:.3f}', fontsize=12)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def deprocess_image(x):\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "    x *= 255\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def save_history(history, fn):\n",
        "    try:\n",
        "        with open(fn, 'wb') as fw:\n",
        "            pickle.dump(history.history, fw, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving history: {e}\")\n",
        "\n",
        "def load_history(fn):\n",
        "    class Temp:\n",
        "        pass\n",
        "    history = Temp()\n",
        "    try:\n",
        "        with open(fn, 'rb') as fr:\n",
        "            history.history = pickle.load(fr)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading history: {e}\")\n",
        "    return history\n",
        "\n",
        "def jitter(img, amount=32):\n",
        "    ox, oy = np.random.randint(-amount, amount + 1, 2)\n",
        "    return np.roll(np.roll(img, ox, axis=1), oy, axis=0), ox, oy\n",
        "\n",
        "def reverse_jitter(img, ox, oy):\n",
        "    return np.roll(np.roll(img, -ox, axis=1), -oy, axis=0)\n",
        "\n",
        "def plot_image(img, title=''):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definici贸n y Compilaci贸n del Modelo en Keras\n",
        "\n",
        "### 1. Importar Librer铆as Necesarias\n",
        "\n",
        "Este c贸digo utiliza `Sequential`, `Conv2D`, `MaxPooling2D`, `Flatten`, `Dropout`, y `Dense` de `tensorflow.keras`, que son componentes esenciales para construir y entrenar redes neuronales convolucionales.\n",
        "\n",
        "### 2. Definir el Modelo\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zHn0Cavc1gVU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Un8kcGL1NYSv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Definir el modelo\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_1',\n",
        "                 input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D((2, 2), name='maxpool_1'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='conv_2'))\n",
        "model.add(MaxPooling2D((2, 2), name='maxpool_2'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_3'))\n",
        "model.add(MaxPooling2D((2, 2), name='maxpool_3'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_4'))\n",
        "model.add(MaxPooling2D((2, 2), name='maxpool_4'))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu', name='dense_1'))\n",
        "model.add(Dense(256, activation='relu', name='dense_2'))\n",
        "model.add(Dense(1, activation='sigmoid', name='output'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definici贸n de Directorios de Datos\n",
        "\n",
        "El siguiente c贸digo establece las rutas a los directorios que contienen los datos de entrenamiento, validaci贸n y prueba para el modelo. Estos directorios son cruciales para cargar y organizar los datos de manera adecuada durante el entrenamiento y la evaluaci贸n del modelo.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g51KJI4k1gto"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G2hDPXb4Noh8"
      },
      "outputs": [],
      "source": [
        "# Directorios de datos\n",
        "base_dir = '/content/cats_and_dogs_small/dogvscat_small'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FdQxxLXQ1hfx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pDvaA42fkQKM"
      },
      "outputs": [],
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1WM5Nzo71ik6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Sg1MHoxWinEy"
      },
      "outputs": [],
      "source": [
        "#Contar im谩genes de entrenamiento y validaci贸n\n",
        "def count_images(directory):\n",
        "    count = 0\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "train_image_count = count_images(train_dir)\n",
        "validation_image_count = count_images(validation_dir)\n",
        "print(f\"Number of training images: {train_image_count}\")\n",
        "print(f\"Number of validation images: {validation_image_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wCldN5wg1jCc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uFRgNuM6iu-3"
      },
      "outputs": [],
      "source": [
        "#Calcular los lotes por 茅pocas\n",
        "batch_size = 20\n",
        "train_batches_per_epoch = train_image_count // batch_size\n",
        "validation_batches_per_epoch = validation_image_count // batch_size\n",
        "print(f\"Number of batches per epoch for training: {train_batches_per_epoch}\")\n",
        "print(f\"Number of batches per epoch for validation: {validation_batches_per_epoch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eUlVVBJ71jkM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R-brV073ee4t"
      },
      "outputs": [],
      "source": [
        "# Verificar que los directorios existan\n",
        "for directory in [train_dir, validation_dir, test_dir]:\n",
        "    if not os.path.exists(directory):\n",
        "        raise FileNotFoundError(f\"Directorio no encontrado: {directory}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iitMKQvq1kGM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JqdB18DDfwnm"
      },
      "outputs": [],
      "source": [
        "!ls /content/cats_and_dogs_small/dogvscat_small"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JW-SXQB41ktN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yBZ9r5sQefIG"
      },
      "outputs": [],
      "source": [
        "# Preparaci贸n de los generadores de datos\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vbthY5V-1loU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UEODetq7mI0Z"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=10,  # N煤mero de lotes por 茅poca\n",
        "    epochs=10,  # N煤mero total de 茅pocas\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=5,  # N煤mero de lotes de validaci贸n por 茅poca\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V42KeZNi1l-z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8OYTfob9mI3c"
      },
      "outputs": [],
      "source": [
        "model.save('model.keras')\n",
        "save_history(history, 'history.bin')\n",
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zAoyJAA11mn0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KrnjsuTc5yi1"
      },
      "outputs": [],
      "source": [
        "history = load_history('history.bin')\n",
        "plot_compare(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fb1H7RKM1nKF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nw3R4JmA5ymW"
      },
      "outputs": [],
      "source": [
        "model_aug = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_1', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D((2, 2), name='maxpool_1'),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same', name='conv_2'),\n",
        "    MaxPooling2D((2, 2), name='maxpool_2'),\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_3'),\n",
        "    MaxPooling2D((2, 2), name='maxpool_3'),\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_4'),\n",
        "    MaxPooling2D((2, 2), name='maxpool_4'),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu', name='dense_1'),\n",
        "    Dense(256, activation='relu', name='dense_2'),\n",
        "    Dense(1, activation='sigmoid', name='output')\n",
        "])\n",
        "\n",
        "model_aug.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KD5SKPAg1nn_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WJbY3TAc5ypw"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IrVBPeJs1n9g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W77AvWTH5ys-"
      },
      "outputs": [],
      "source": [
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rpm0Lg021oS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MaMPjnIf5ywQ"
      },
      "outputs": [],
      "source": [
        "# early_stop = EarlyStopping(monitor='val_loss', patience=6, verbose=1)\n",
        "######################################### change the values 100, 60 and 50\n",
        "history_aug = model_aug.fit(train_generator, steps_per_epoch=100, epochs=60,\n",
        "                                      validation_data=validation_generator, validation_steps=50, verbose=1)\n",
        "#history_aug = model_aug.fit(train_generator, steps_per_epoch=100, epochs=60,\n",
        "#                                      validation_data=validation_generator, validation_steps=50, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nTe3Vu3Y1os3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca6Aw0__5yzF"
      },
      "outputs": [],
      "source": [
        "model_aug.save('model_aug.keras')\n",
        "save_history(history_aug, 'history_aug.bin')\n",
        "print(history_aug.history.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4XplhNJA1pFM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHfODJDQmI9e"
      },
      "outputs": [],
      "source": [
        "history_aug = load_history('history_aug.bin')\n",
        "plot_compare(history_aug, steps=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xiL1fNGi1pXA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS7otsOCMyC6"
      },
      "outputs": [],
      "source": [
        "# Evaluar el modelo en el conjunto de validaci贸n\n",
        "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
        "print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ARnppPxT1p92"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtQTHwqOMyGA"
      },
      "outputs": [],
      "source": [
        "# Realizar predicciones con el modelo\n",
        "sample_image_path = '/content/cats_and_dogs_small/dogvscat_small/train/cats/53.jpg'\n",
        "img = image.load_img(sample_image_path, target_size=(150, 150))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Rescale"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KQO8hlCV1qXF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh9Wvd39MyIi"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(img_array)\n",
        "print(f'Predicci贸n: {\"Perro\" if prediction[0] > 0.5 else \"Gato\"}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QiFZ2ehn1qxb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU_SuiZrMyOC"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img_array[0])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZFXNNgdU1rIU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd6heiNRMyQU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "# Load the VGG16 model with ImageNet weights, without the top classification layer\n",
        "vgg = VGG16(weights='imagenet', include_top=False)\n",
        "vgg.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y0O4-lWz1r4g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkKYCjiZSD_r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KKbSJ9qD1sIi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFKod86gRkIX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the VGG16 model with ImageNet weights, without the top classification layer\n",
        "vgg = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "# Extract the outputs of the convolutional layers\n",
        "layer_outputs = [layer.output for layer in vgg.layers if 'conv1' in layer.name]\n",
        "\n",
        "# Create a new model that outputs the features from the specified layers\n",
        "activation_model = Model(inputs=vgg.input, outputs=layer_outputs)\n",
        "\n",
        "# Assuming img_tensor is the preprocessed image tensor\n",
        "intermediate_activations = activation_model.predict(img_array)\n",
        "\n",
        "first_layer_activation = intermediate_activations[0]\n",
        "\n",
        "plt.imshow(first_layer_activation[0, :, :, 19], cmap='viridis')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AtDKXjlk2c1v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFx6NMvWRkLb"
      },
      "outputs": [],
      "source": [
        "layer_names = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "\n",
        "layer_outputs = [layer.output for layer in vgg.layers if layer.name in layer_names]\n",
        "activation_model = Model(inputs=vgg.input, outputs=layer_outputs)\n",
        "intermediate_activations = activation_model.predict(img_array)\n",
        "\n",
        "images_per_row = 8\n",
        "max_images = 8\n",
        "# Now let's display our feature maps\n",
        "for layer_name, layer_activation in zip(layer_names, intermediate_activations):\n",
        "    # This is the number of features in the feature map\n",
        "    n_features = layer_activation.shape[-1]\n",
        "    n_features = min(n_features, max_images)\n",
        "\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = layer_activation.shape[1]\n",
        "\n",
        "    # We will tile the activation channels in this matrix\n",
        "    n_cols = n_features // images_per_row\n",
        "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "\n",
        "    # We'll tile each filter into this big horizontal grid\n",
        "    for col in range(n_cols):\n",
        "        for row in range(images_per_row):\n",
        "            channel_image = layer_activation[0,\n",
        "                                             :, :,\n",
        "                                             col * images_per_row + row]\n",
        "            # Post-process the feature to make it visually palatable\n",
        "            channel_image -= channel_image.mean()\n",
        "            channel_image /= channel_image.std()\n",
        "            channel_image *= 64\n",
        "            channel_image += 128\n",
        "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "            display_grid[col * size : (col + 1) * size,\n",
        "                         row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "    # Display the grid\n",
        "    scale = 2. / size\n",
        "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
        "                        scale * display_grid.shape[0]))\n",
        "    plt.axis('off')\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZDRdVsFB2eRG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiXZnlwWRkOG"
      },
      "outputs": [],
      "source": [
        "# Cargar el modelo VGG16 con pesos preentrenados de ImageNet\n",
        "model = VGG16(weights='imagenet', include_top=True)\n",
        "\n",
        "# Buscar el 铆ndice de la capa 'predictions' por nombre\n",
        "layer_idx = None\n",
        "for i, layer in enumerate(model.layers):\n",
        "    if layer.name == 'predictions':\n",
        "        layer_idx = i\n",
        "        break\n",
        "\n",
        "if layer_idx is None:\n",
        "    raise ValueError(\"Layer 'predictions' not found in the model.\")\n",
        "\n",
        "# Cambiar la activaci贸n softmax a lineal\n",
        "model.layers[layer_idx].activation = activations.linear"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pXsvQPBa2e8x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zuw9mF7RkTw"
      },
      "outputs": [],
      "source": [
        "from tf_keras_vis.activation_maximization import ActivationMaximization\n",
        "from tf_keras_vis.utils.callbacks import Print\n",
        "\n",
        "# Definir la funci贸n de p茅rdida para maximizar la activaci贸n del filtro 20\n",
        "def loss(output):\n",
        "    return output[:, 20]\n",
        "\n",
        "# Configurar la visualizaci贸n de activaciones\n",
        "activation_maximization = ActivationMaximization(model, model_modifier=None, clone=False)\n",
        "\n",
        "# Visualizar la activaci贸n del filtro (por ejemplo, el filtro 20)\n",
        "img = activation_maximization(loss, callbacks=[Print(interval=50)])\n",
        "\n",
        "# Mostrar la imagen generada\n",
        "plot_image(img[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4LaETD7G2fUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvEZKbJ2RkWi"
      },
      "outputs": [],
      "source": [
        "from tf_keras_vis.utils.modifiers import Jitter\n",
        "\n",
        "# Definir la funci贸n de p茅rdida para maximizar la activaci贸n del filtro 20 (ouzel)\n",
        "def loss(output):\n",
        "    return output[:, 20]  # 20 es la categor铆a de ImageNet para 'ouzel'\n",
        "\n",
        "# Configurar la visualizaci贸n de activaciones con jitter\n",
        "activation_maximization = ActivationMaximization(model, model_modifier=None, clone=False)\n",
        "\n",
        "# Aplicar jitter de 16 p铆xeles durante el proceso de optimizaci贸n\n",
        "img = activation_maximization(\n",
        "    loss,\n",
        "    callbacks=[Print(interval=50)],\n",
        "    input_modifiers=[Jitter(16)],  # Jitter de 16 p铆xeles\n",
        "    steps=400  # N煤mero de iteraciones para optimizar\n",
        ")\n",
        "\n",
        "# Mostrar la imagen generada\n",
        "plot_image(img[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKdoRa-eRkZp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUwZoXHORkeQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTL_g7Ngkaxe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}